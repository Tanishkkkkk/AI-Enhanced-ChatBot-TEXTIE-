ğŸ“Œ TEXTIE â€“ Gen-Z AI Chatbot (Local LLM)

TEXTIE is an AI-enhanced conversational chatbot designed to deliver Gen-Z friendly, natural, and engaging conversations using a locally hosted Large Language Model.
The project focuses on personality-driven interaction, offline execution, and resource-efficient inference.

Unlike cloud-based chatbots, TEXTIE runs fully on local infrastructure, making it fast, private, and cost-free.

âœ¨ Key Features

ğŸ§  Gen-Z Customized Personality
Casual, friendly, slang-aware responses for natural interaction

ğŸ’» Local LLM Execution
Runs using LM Studio with Gamma AI model

âš¡ Low Fragment / Context Optimization
Faster responses with minimal hardware usage

ğŸ”’ Offline & Privacy-Focused
No cloud calls, no data leakage

ğŸ§© Modular & Extensible Design
Easy to extend with memory, agents, or emotion analysis

ğŸ› ï¸ Tech Stack

LLM: Gamma AI

Model Hosting: LM Studio (Local Inference)

Language: Python

Inference Mode: Local REST / API (LM Studio)

Design Goal: Lightweight, fast, personality-driven AI

ğŸ§  Why TEXTIE?

Most chatbots prioritize accuracy but feel robotic.
TEXTIE focuses on how AI talks, not just what it says.

This project demonstrates:

Practical use of local LLMs

Prompt engineering for personality shaping

Optimization for low-resource environments

Human-centric AI design

ğŸš€ Future Enhancements

Long-term conversational memory

Emotion and intent detection

Agent-based task execution

Web / Mobile UI integration

Multi-model support (Mistral, LLaMA, etc.)

ğŸ“¸ Demo (Optional but Powerful)

Add screenshots or a short GIF of the chatbot running.

ğŸ§‘â€ğŸ’» Author

Tanishk Mishra
B.Tech â€“ AI & Robotics
Exploring applied AI, agentic systems, and human-centric AI design.
